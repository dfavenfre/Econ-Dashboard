{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHH4AzcPQ2yn"
      },
      "source": [
        "# ‚öõ Packages and Important Libraries ‚öõ\n",
        "The imported libraries contain various modules that are helpful for model building in tensorflow and for data, financial_phrasebank dataset from Huggingface is downloaded. Important resources can be found down below.\n",
        "\n",
        "*   https://huggingface.co/datasets/financial_phrasebank (Financial PhraseBank Dataset)\n",
        "*   https://medium.com/prosus-ai-tech-blog/finbert-financial-sentiment-analysis-with-bert-b277a3607101 (FinBERT Article)\n",
        "*   https://medium.com/mlearning-ai/optimizing-deep-learning-models-with-pruning-a-practical-guide-163e990c02af (Model Pruning in TF)\n",
        "\n",
        "Complete list of libraries and modules are;\n",
        "*  tensorflow.keras.layers,  tensorflow.keras.models, tensorflow.keras.utils, sklearn.metrics, sklearn.model_selection\n",
        "*  nltk, string, re, random, io, pandas, numpy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CCYxagt_ACp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ed91314-f1b8-47db-c5c6-e788a9afeaa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n",
            "Collecting aiohttp (from datasets)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0.0,>=0.11.0 (from datasets)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Collecting responses<0.19 (from datasets)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, huggingface-hub, aiosignal, aiohttp, datasets\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 huggingface-hub-0.15.1 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.1.0)\n",
            "--2023-06-04 20:56:25--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-06-04 20:56:25 (93.0 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# model packages\n",
        "!pip install datasets\n",
        "!pip install imbalanced-learn\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Embedding, Attention\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from keras.utils import pad_sequences\n",
        "from helper_functions import create_tensorboard_callback\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import layers, models, utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# data preprocessing packages\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# uploading data\n",
        "import random\n",
        "import re\n",
        "import io\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from datasets import load_dataset\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZLPon7DZ4rk"
      },
      "outputs": [],
      "source": [
        "# create a directory to save TensorBoard Logs\n",
        "SAVE_DIR = \"model_logs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA9eQ_wCSxVC"
      },
      "source": [
        "# Useful Functions ‚õΩ\n",
        "\n",
        "\n",
        "\n",
        "*   **text_cleaning(text)** : Clean and remove unnecessary string elements from each sentence, and return it back to the original sentence data\n",
        "*   **calculate_results(y_true, y_pred)** :  Calculate various classification scores, including Accuracy, F1_score, Recall, and Precision.\n",
        "\n",
        "An addition to weight parameter for \"precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\", since the target variables (labels) might be imbalanced, setting average parameter to \"weighted\" solves the imbalance issue for us.   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVT-apGEz8mr"
      },
      "outputs": [],
      "source": [
        "def text_cleaning(text):\n",
        "\n",
        "  \"\"\" Clean and remove unnecessary string elements from each sentence, and return it back to the original sentence data.\"\"\"\n",
        "\n",
        "  text = re.sub(r'@[A-Za-z0-9]+', '', text)     # removing @mentions\n",
        "  text = re.sub(r'@[A-Za-zA-Z0-9]+', '', text)  # removing @mentions\n",
        "  text = re.sub(r'@[A-Za-z]+', '', text)        # removing @mentions\n",
        "  text = re.sub(r'@[-)]+', '', text)            # removing @mentions\n",
        "  text = re.sub(r'#', '', text )                # removing '#' sign\n",
        "  text = re.sub(r'RT[\\s]+', '', text)           # removing RT\n",
        "  text = re.sub(r'https?\\/\\/\\S+', '', text)     # removing the hyper link\n",
        "  text = re.sub(r'&[a-z;]+', '', text)          # removing '&gt;'\n",
        "\n",
        "  return text\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "\n",
        "  \"\"\" Calculate various classification scores, including Accuracy, F1_score, Recall, and Precision.\"\"\"\n",
        "\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": round(model_accuracy,3),\n",
        "                    \"precision\": round(model_precision,3),\n",
        "                    \"recall\": round(model_recall,3),\n",
        "                    \"f1\": round(model_f1,3)}\n",
        "  return model_results\n",
        "\n",
        "def pre_process(data):\n",
        "\n",
        "  \"\"\" Alternative to text_cleaning(), does the same job\"\"\"\n",
        "\n",
        "  # Convert all text to lowercase\n",
        "  data = data.str.lower()\n",
        "\n",
        "  # Remove numbers\n",
        "  data = data.apply(lambda x: re.sub(r'\\d+', '', x))\n",
        "\n",
        "  # Remove punctuation\n",
        "  punctuation = string.punctuation.replace(\"'\", \"\")\n",
        "  data = data.apply(lambda x: x.translate(str.maketrans('', '', punctuation)))\n",
        "\n",
        "  # Remove $\n",
        "  punctuation = string.punctuation.replace(\"$\", \"\")\n",
        "  data = data.apply(lambda x: x.translate(str.maketrans('', '', punctuation)))\n",
        "\n",
        "  # Remove stop words\n",
        "  nltk.download('stopwords')\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  data = data.apply(lambda x: \" \".join(word for word in x.split() if word not in stop_words))\n",
        "\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9HQhAVPUNt9"
      },
      "source": [
        "# Upload Financial_Phrasebank Data ü§ó"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "efcc119688f345fc9f4d9126933d2258",
            "bdacd15065234bc0a71805cd9325ab9c",
            "59ec37c2e0564e4a8580526b3d523701",
            "a79ad42126ba4a248ab77dc75a9d8f12",
            "bd1186d7c00246579ba7c6976d2f8c72",
            "e499edc3f4394b68820ebb01f9735f52",
            "acd34cfac9154a498c58c1dadb66eb13",
            "9d434b7eeb704df9aa3c12f5d24c9b5d",
            "402a4389303a40d0b17def8396c2eb9f",
            "f2351273be234e55930b3b4fe277e60b",
            "3deb94759a5f40a0a9fa076c6877cca9",
            "42c870a81ee245b88b53155765e26d4f",
            "591ffb4ff7ee4b528a89d8e6cf75dbc0",
            "07e8ac75f5de4d1fabb6e9172d19fdc2",
            "3c58f941015a406da70da053b7f63afd",
            "baaf35b900214704b8c0ccf82c17e6f7",
            "a5d012481a7d42a7bc72bdf00d5fca07",
            "30dd8ea95c844923bdf33c8e42f9ebd9",
            "77c1dd200e1c447f99ecb089195c9f35",
            "ffcc31969d5644f6880255dd4aee244a",
            "7db708f443b245bb9bd24628b390a4c9",
            "f9be036b02f043c187385f20bb00d6d5",
            "aeef23977b2d4828b4f89a312029212c",
            "05320d75302742eeb69c2cd9456092de",
            "1008ddc7f2cd4011a818cf994018fe81",
            "0ec5638f5213410196a108c75762d1a2",
            "eda0c5000afa4c588d9c7e6d2d34f541",
            "8050e31397284a01b14a5e5e9f06064e",
            "4c88bceaa5484508af53002abf178a86",
            "b12a98e063b44426b3903666222b85b6",
            "0a4e813ddc33413daaf58572307348dc",
            "9eed08f45616429b9c2a9a5829b9db73",
            "7013188432034adbb4a642e24bf421f7",
            "5b08d3aeeaed48e5a9af2aef36626e99",
            "4a92e8bfbca2440abfc82eb8d17000ae",
            "ad75b56b854c46f084c5188dc9f2302b",
            "c7927e077c3d474f8ced40e66b833444",
            "dad7c5211b4c41ba91d4feaac29d95d0",
            "5b77c9577864495da27320e0d05a96cb",
            "6b9c1df2079f4541bc830939a8be75a1",
            "4094b8253cb04bf49094298a9199e55e",
            "8f514b7f067d4f3e8111ffd2c39a77d6",
            "35828cc245094b9392ccf2289a70fd37",
            "16e8af8f1a424486b5dfb31d6ef76b0f",
            "88ac45ec2b9a4a10be05411c8566e212",
            "57d5660d2c09442cbe8a5a245e13ee14",
            "a5bac504e92343888d33a30b3ecd85d9",
            "d72df805764c4a5bafd6880e888cbfee",
            "fc351daac76442db9656b804b6cd2104",
            "b1f86fe5b1f1448d871f43e19e942326",
            "ce7de1d44deb4be287203625d1634dd5",
            "f243d19b0c3d42ae9f2f8e6b9ecfd4fe",
            "f582e96ab67746028d6c6c797dd8fab7",
            "67b453aca47a40e694d19abbc38ee323",
            "8509d65370ff4e9fb7ecc4b460c163ff"
          ]
        },
        "id": "XYcyY31IQU5S",
        "outputId": "dcffc281-c651-4fa5-cd84-5e57f8faabdf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.04k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efcc119688f345fc9f4d9126933d2258"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/13.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42c870a81ee245b88b53155765e26d4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/8.86k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aeef23977b2d4828b4f89a312029212c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset financial_phrasebank/sentences_allagree to /root/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/682k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b08d3aeeaed48e5a9af2aef36626e99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2264 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ac45ec2b9a4a10be05411c8566e212"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset financial_phrasebank downloaded and prepared to /root/.cache/huggingface/datasets/financial_phrasebank/sentences_allagree/1.0.0/550bde12e6c30e2674da973a55f57edde5181d53f5a5a34c1531c53f93b7e141. Subsequent calls will reuse this data.\n",
            "Total Number of Sentences is: 2264\n"
          ]
        }
      ],
      "source": [
        "# load the data using load_dataset\n",
        "dataset = load_dataset(\"financial_phrasebank\",\"sentences_allagree\",split=\"train\")\n",
        "# Convert the DatasetDict to a Pandas dataframe (named it after HuggingFace DataFrame)\n",
        "text_df = pd.DataFrame(dataset)\n",
        "print(\"Total Number of Sentences is: {}\".format(len(text_df[\"sentence\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxpg3g-KaAjY",
        "outputId": "5304fc1d-22f8-47b9-982c-4c27e3687ae2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.614399\n",
              "2    0.251767\n",
              "0    0.133834\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Display the dataframe\n",
        "text_df[\"label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Caqjc8B-ZF4y",
        "outputId": "63dcfb58-7845-458a-b312-f366bbc7e70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# clean and split huggingface dataset into training and validation\n",
        "sentences = pre_process(text_df[\"sentence\"])\n",
        "X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(sentences,\n",
        "                                                                    text_df[\"label\"],\n",
        "                                                                    test_size=0.1,\n",
        "                                                                    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEVrNaJrZoVe"
      },
      "source": [
        "# Upload Economic Sentiment text from Kaggle ‚öì"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ST2wQFf2P8zg"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "text_df = pd.read_csv(io.BytesIO(uploaded['economic_sentiment_text.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGWsS15iUeIL"
      },
      "outputs": [],
      "source": [
        "# clean and split economic sentiment dataset into training and validation\n",
        "text_df[\"Sentiment\"] = text_df[\"Sentiment\"].replace({\"neutral\":0, \"positive\":1, \"negative\":2})\n",
        "text_df[\"Sentiment\"].value_counts(normalize=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uq5lpfw_PYX"
      },
      "outputs": [],
      "source": [
        "sentences = pre_process(text_df[\"Sentence\"])\n",
        "X_train_pre, X_test_pre, y_train_pre, y_test_pre = train_test_split(sentences,text_df[\"Sentiment\"],test_size=0.1,random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoSvQi5zbHnN"
      },
      "source": [
        "# Data Pre-processing with Tensorflow Tokenizer üìë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f03aZbzS9Is",
        "outputId": "9eca07c2-6094-489a-9599-5c26da0ba723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The max length is:  36\n"
          ]
        }
      ],
      "source": [
        "# Initialize the tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Fit the tokenizer on the training data\n",
        "tokenizer.fit_on_texts(X_train_pre)\n",
        "\n",
        "# Convert the text data to sequences\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_pre)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test_pre)\n",
        "\n",
        "# Find max length\n",
        "max_length = max(len(seq) for seq in X_train_seq)\n",
        "print(\"The max length is: \", max_length)\n",
        "\n",
        "# Pad the sequences to have the same length\n",
        "X_train = pad_sequences(X_train_seq, max_length)\n",
        "X_test = pad_sequences(X_test_seq, max_length)\n",
        "\n",
        "# converting target variables into categorical values\n",
        "y_train = to_categorical(y_train_pre, num_classes=3)\n",
        "y_test = to_categorical(y_test_pre, num_classes=3)\n",
        "\n",
        "# Balance the labels\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaorurNwg8Oj"
      },
      "source": [
        "# Baseline Model (Dense) ‚ö´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eyBG0Na121T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2fff5f-7010-48ee-ff62-30ea6371323b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 36)]              0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 36, 256)           2560000   \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 36, 256)           0         \n",
            "                                                                 \n",
            " global_average_pooling1d_4   (None, 256)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,642,435\n",
            "Trainable params: 2,642,435\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# construct the model architecture\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "x = layers.Embedding(input_dim=10000, output_dim=256, input_length=max_length)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Dense(256, activation=\"relu\")(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model = models.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFTbvlv_aE9F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "274b7262-b887-47b4-cc3b-27729ac8c2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 1.0904 - accuracy: 0.3839\n",
            "Epoch 1: val_loss improved from inf to 1.04037, saving model to dense_model_checkpoints/model-01-0.384.hdf5\n",
            "30/30 [==============================] - 8s 230ms/step - loss: 1.0904 - accuracy: 0.3839 - val_loss: 1.0404 - val_accuracy: 0.6784 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.9940 - accuracy: 0.5308\n",
            "Epoch 2: val_loss improved from 1.04037 to 0.81521, saving model to dense_model_checkpoints/model-02-0.531.hdf5\n",
            "30/30 [==============================] - 9s 305ms/step - loss: 0.9940 - accuracy: 0.5308 - val_loss: 0.8152 - val_accuracy: 0.6960 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.8135 - accuracy: 0.5931\n",
            "Epoch 3: val_loss did not improve from 0.81521\n",
            "30/30 [==============================] - 6s 197ms/step - loss: 0.8135 - accuracy: 0.5931 - val_loss: 0.8833 - val_accuracy: 0.6608 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.7489 - accuracy: 0.6142\n",
            "Epoch 4: val_loss improved from 0.81521 to 0.65927, saving model to dense_model_checkpoints/model-04-0.614.hdf5\n",
            "30/30 [==============================] - 8s 262ms/step - loss: 0.7489 - accuracy: 0.6142 - val_loss: 0.6593 - val_accuracy: 0.7004 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.6897 - accuracy: 0.6445\n",
            "Epoch 5: val_loss did not improve from 0.65927\n",
            "30/30 [==============================] - 3s 105ms/step - loss: 0.6897 - accuracy: 0.6445 - val_loss: 0.6628 - val_accuracy: 0.7357 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.6375 - accuracy: 0.6862\n",
            "Epoch 6: val_loss improved from 0.65927 to 0.61143, saving model to dense_model_checkpoints/model-06-0.686.hdf5\n",
            "30/30 [==============================] - 2s 57ms/step - loss: 0.6375 - accuracy: 0.6862 - val_loss: 0.6114 - val_accuracy: 0.7357 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5963 - accuracy: 0.7228\n",
            "Epoch 7: val_loss did not improve from 0.61143\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.5963 - accuracy: 0.7228 - val_loss: 0.6266 - val_accuracy: 0.7621 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7517\n",
            "Epoch 8: val_loss improved from 0.61143 to 0.57769, saving model to dense_model_checkpoints/model-08-0.752.hdf5\n",
            "30/30 [==============================] - 2s 62ms/step - loss: 0.5380 - accuracy: 0.7517 - val_loss: 0.5777 - val_accuracy: 0.7753 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4897 - accuracy: 0.7887\n",
            "Epoch 9: val_loss did not improve from 0.57769\n",
            "30/30 [==============================] - 2s 81ms/step - loss: 0.4897 - accuracy: 0.7887 - val_loss: 0.5973 - val_accuracy: 0.7797 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8162\n",
            "Epoch 10: val_loss improved from 0.57769 to 0.56213, saving model to dense_model_checkpoints/model-10-0.816.hdf5\n",
            "30/30 [==============================] - 3s 97ms/step - loss: 0.4344 - accuracy: 0.8162 - val_loss: 0.5621 - val_accuracy: 0.7885 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3980 - accuracy: 0.8422\n",
            "Epoch 11: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 2s 53ms/step - loss: 0.3980 - accuracy: 0.8422 - val_loss: 0.5950 - val_accuracy: 0.7841 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3695 - accuracy: 0.8443\n",
            "Epoch 12: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3695 - accuracy: 0.8443 - val_loss: 0.5786 - val_accuracy: 0.8106 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.8475\n",
            "Epoch 13: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.3493 - accuracy: 0.8475 - val_loss: 0.5826 - val_accuracy: 0.7974 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8694\n",
            "Epoch 14: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 1s 45ms/step - loss: 0.3196 - accuracy: 0.8694 - val_loss: 0.6002 - val_accuracy: 0.7885 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2992 - accuracy: 0.8799\n",
            "Epoch 15: val_loss did not improve from 0.56213\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2992 - accuracy: 0.8799 - val_loss: 0.6846 - val_accuracy: 0.7577 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.8868\n",
            "Epoch 16: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2785 - accuracy: 0.8868 - val_loss: 0.6282 - val_accuracy: 0.7753 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 0.8890\n",
            "Epoch 17: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2711 - accuracy: 0.8890 - val_loss: 0.6450 - val_accuracy: 0.7665 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "25/30 [========================>.....] - ETA: 0s - loss: 0.2614 - accuracy: 0.8956\n",
            "Epoch 18: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.2643 - accuracy: 0.8930 - val_loss: 0.6344 - val_accuracy: 0.7753 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.8879\n",
            "Epoch 19: val_loss did not improve from 0.56213\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2679 - accuracy: 0.8879 - val_loss: 0.6416 - val_accuracy: 0.7797 - lr: 1.0000e-04\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.8844\n",
            "Epoch 20: val_loss did not improve from 0.56213\n",
            "\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "30/30 [==============================] - 2s 52ms/step - loss: 0.2725 - accuracy: 0.8844 - val_loss: 0.6367 - val_accuracy: 0.7753 - lr: 1.0000e-04\n",
            "Epoch 20: early stopping\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "model_history_hf = model.fit(X_resampled, y_resampled,\n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
        "                        filepath=\"dense_model_checkpoints/model-{epoch:02d}-{accuracy:.3f}.hdf5\",\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        save_best_only=True,\n",
        "                        verbose=1\n",
        "                    ),\n",
        "                    # learning rate drop\n",
        "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        factor=0.1,\n",
        "                        patience=5,\n",
        "                        verbose=1,\n",
        "                        min_lr=0.000001\n",
        "                    ),\n",
        "                    # early stopping\n",
        "                    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        min_delta=0.001,\n",
        "                        patience=10,\n",
        "                        verbose=1,\n",
        "                    ),\n",
        "                    # CSV logger\n",
        "                    tf.keras.callbacks.CSVLogger(\n",
        "                        filename=\"dense_model_training_log.csv\",\n",
        "                        separator=\",\",\n",
        "                        append=False\n",
        "                    )])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtK7BVJAX1_A",
        "outputId": "7d766c17-8fd9-4dfe-a47c-f3158e1c2c0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "best_dense_model = tf.keras.models.load_model(\"/content/dense_model_checkpoints/model-10-0.816.hdf5\")\n",
        "\n",
        "# predict\n",
        "model_1_preds_probs = best_dense_model.predict(X_test)\n",
        "# convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_preds_probs))\n",
        "# calculate model_1 results\n",
        "model_1 = calculate_results(y_test, model_1_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTUnvXRtMNYS"
      },
      "source": [
        "# Model 2 (LSTM) ‚¨õ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq3YzuPrtsMt",
        "outputId": "f040f596-24ba-43a1-b031-029670bdf8ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 36)]              0         \n",
            "                                                                 \n",
            " embedding_12 (Embedding)    (None, 36, 256)           2560000   \n",
            "                                                                 \n",
            " dropout_24 (Dropout)        (None, 36, 256)           0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 36, 256)           525312    \n",
            "                                                                 \n",
            " dropout_25 (Dropout)        (None, 36, 256)           0         \n",
            "                                                                 \n",
            " global_average_pooling1d_12  (None, 256)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,118,595\n",
            "Trainable params: 3,118,595\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# construct the model architecture\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "x = layers.Embedding(input_dim=10000, output_dim=256, input_length=max_length)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.LSTM(256, activation=\"relu\", return_sequences=True)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "\n",
        "model_lstm = models.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_lstm.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3hU3ADUMMi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "318a36ad-4e9c-41ee-e659-96d0f4822977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 1.0741 - accuracy: 0.4050\n",
            "Epoch 1: val_loss improved from inf to 0.91801, saving model to lstm_model_checkpoints/model-01-0.405.hdf5\n",
            "30/30 [==============================] - 9s 231ms/step - loss: 1.0741 - accuracy: 0.4050 - val_loss: 0.9180 - val_accuracy: 0.7313 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.8827 - accuracy: 0.5610\n",
            "Epoch 2: val_loss improved from 0.91801 to 0.84704, saving model to lstm_model_checkpoints/model-02-0.561.hdf5\n",
            "30/30 [==============================] - 6s 196ms/step - loss: 0.8827 - accuracy: 0.5610 - val_loss: 0.8470 - val_accuracy: 0.6652 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.6057\n",
            "Epoch 3: val_loss improved from 0.84704 to 0.67463, saving model to lstm_model_checkpoints/model-03-0.606.hdf5\n",
            "30/30 [==============================] - 6s 192ms/step - loss: 0.7381 - accuracy: 0.6057 - val_loss: 0.6746 - val_accuracy: 0.7357 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.6531 - accuracy: 0.6351\n",
            "Epoch 4: val_loss improved from 0.67463 to 0.63436, saving model to lstm_model_checkpoints/model-04-0.635.hdf5\n",
            "30/30 [==============================] - 6s 201ms/step - loss: 0.6531 - accuracy: 0.6351 - val_loss: 0.6344 - val_accuracy: 0.6740 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.6477\n",
            "Epoch 5: val_loss improved from 0.63436 to 0.63214, saving model to lstm_model_checkpoints/model-05-0.648.hdf5\n",
            "30/30 [==============================] - 4s 140ms/step - loss: 0.6007 - accuracy: 0.6477 - val_loss: 0.6321 - val_accuracy: 0.7445 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5686 - accuracy: 0.6677\n",
            "Epoch 6: val_loss did not improve from 0.63214\n",
            "30/30 [==============================] - 5s 171ms/step - loss: 0.5686 - accuracy: 0.6677 - val_loss: 0.6499 - val_accuracy: 0.6960 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5448 - accuracy: 0.6752\n",
            "Epoch 7: val_loss did not improve from 0.63214\n",
            "30/30 [==============================] - 3s 117ms/step - loss: 0.5448 - accuracy: 0.6752 - val_loss: 0.7182 - val_accuracy: 0.7489 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5120 - accuracy: 0.6950\n",
            "Epoch 8: val_loss did not improve from 0.63214\n",
            "30/30 [==============================] - 5s 148ms/step - loss: 0.5120 - accuracy: 0.6950 - val_loss: 0.7425 - val_accuracy: 0.7137 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.7164\n",
            "Epoch 9: val_loss improved from 0.63214 to 0.61571, saving model to lstm_model_checkpoints/model-09-0.716.hdf5\n",
            "30/30 [==============================] - 4s 143ms/step - loss: 0.5184 - accuracy: 0.7164 - val_loss: 0.6157 - val_accuracy: 0.7753 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.7517\n",
            "Epoch 10: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 3s 116ms/step - loss: 0.4881 - accuracy: 0.7517 - val_loss: 0.6733 - val_accuracy: 0.7665 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.7814\n",
            "Epoch 11: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 3s 104ms/step - loss: 0.4337 - accuracy: 0.7814 - val_loss: 0.7901 - val_accuracy: 0.7665 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3946 - accuracy: 0.8133\n",
            "Epoch 12: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 4s 147ms/step - loss: 0.3946 - accuracy: 0.8133 - val_loss: 0.6579 - val_accuracy: 0.7797 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3641 - accuracy: 0.8373\n",
            "Epoch 13: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 3s 100ms/step - loss: 0.3641 - accuracy: 0.8373 - val_loss: 0.7638 - val_accuracy: 0.7401 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8654\n",
            "Epoch 14: val_loss did not improve from 0.61571\n",
            "\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "30/30 [==============================] - 3s 88ms/step - loss: 0.3046 - accuracy: 0.8654 - val_loss: 0.8622 - val_accuracy: 0.7445 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.8895\n",
            "Epoch 15: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 3s 85ms/step - loss: 0.2583 - accuracy: 0.8895 - val_loss: 0.9224 - val_accuracy: 0.7313 - lr: 1.0000e-04\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.8933\n",
            "Epoch 16: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 4s 125ms/step - loss: 0.2511 - accuracy: 0.8933 - val_loss: 0.9370 - val_accuracy: 0.7357 - lr: 1.0000e-04\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9029\n",
            "Epoch 17: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 3s 100ms/step - loss: 0.2359 - accuracy: 0.9029 - val_loss: 0.9403 - val_accuracy: 0.7577 - lr: 1.0000e-04\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.8994\n",
            "Epoch 18: val_loss did not improve from 0.61571\n",
            "30/30 [==============================] - 3s 93ms/step - loss: 0.2335 - accuracy: 0.8994 - val_loss: 0.9720 - val_accuracy: 0.7489 - lr: 1.0000e-04\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.8989\n",
            "Epoch 19: val_loss did not improve from 0.61571\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "30/30 [==============================] - 3s 98ms/step - loss: 0.2297 - accuracy: 0.8989 - val_loss: 1.0132 - val_accuracy: 0.7401 - lr: 1.0000e-04\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "model_history_lstm = model_lstm.fit(X_resampled, y_resampled,\n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs=100,\n",
        "          batch_size=128,\n",
        "          callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
        "                        filepath=\"lstm_model_checkpoints/model-{epoch:02d}-{accuracy:.3f}.hdf5\",\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        save_best_only=True,\n",
        "                        verbose=1\n",
        "                    ),\n",
        "                    # learning rate drop\n",
        "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        factor=0.1,\n",
        "                        patience=5,\n",
        "                        verbose=1,\n",
        "                        min_lr=0.000001\n",
        "                    ),\n",
        "                    # early stopping\n",
        "                    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        min_delta=0.001,\n",
        "                        patience=10,\n",
        "                        verbose=1,\n",
        "                    ),\n",
        "                    # CSV logger\n",
        "                    tf.keras.callbacks.CSVLogger(\n",
        "                        filename=\"lstm_model_training_log.csv\",\n",
        "                        separator=\",\",\n",
        "                        append=False\n",
        "                    )])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnAzxOF4469E",
        "outputId": "13dbd180-1a56-443c-c13b-0ff699421ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "best_lstm_model = tf.keras.models.load_model(\"/content/lstm_model_checkpoints/model-09-0.716.hdf5\")\n",
        "\n",
        "# predict\n",
        "model_2_preds_probs = best_lstm_model.predict(X_test)\n",
        "# convert model prediction probabilities to label format\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_preds_probs))\n",
        "# calculate model_1 results\n",
        "model_2 = calculate_results(y_test, model_2_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLA6IjPCl16d"
      },
      "source": [
        "# Model 3 (GRU) ‚¨õ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EqaQFrwlzWO",
        "outputId": "911fc1cb-17fc-48bb-83c8-13525b4780a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 36)]              0         \n",
            "                                                                 \n",
            " embedding_14 (Embedding)    (None, 36, 128)           1280000   \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 36, 128)           0         \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 36, 128)           99072     \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 36, 128)           0         \n",
            "                                                                 \n",
            " global_average_pooling1d_14  (None, 128)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,379,459\n",
            "Trainable params: 1,379,459\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# construct the model architecture\n",
        "inputs = layers.Input(shape=(max_length, ))\n",
        "x = layers.Embedding(input_dim=10000, output_dim=128, input_length=max_length)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.GRU(128,return_sequences=True)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model_gru = models.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_gru.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "model_gru.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udTPCtTcl9Sj",
        "outputId": "ea9b9d33-919a-4b5b-e676-c9c0977ef30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 1.0529 - accuracy: 0.4200\n",
            "Epoch 1: val_loss improved from inf to 0.96003, saving model to gru_model_checkpoints/model-01-0.420.hdf5\n",
            "59/59 [==============================] - 13s 184ms/step - loss: 1.0529 - accuracy: 0.4200 - val_loss: 0.9600 - val_accuracy: 0.6432 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.8270 - accuracy: 0.5795\n",
            "Epoch 2: val_loss improved from 0.96003 to 0.69295, saving model to gru_model_checkpoints/model-02-0.579.hdf5\n",
            "59/59 [==============================] - 7s 117ms/step - loss: 0.8270 - accuracy: 0.5795 - val_loss: 0.6930 - val_accuracy: 0.6784 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.7096 - accuracy: 0.6239\n",
            "Epoch 3: val_loss improved from 0.69295 to 0.66834, saving model to gru_model_checkpoints/model-03-0.624.hdf5\n",
            "59/59 [==============================] - 5s 82ms/step - loss: 0.7096 - accuracy: 0.6239 - val_loss: 0.6683 - val_accuracy: 0.6784 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6519 - accuracy: 0.6466\n",
            "Epoch 4: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 3s 51ms/step - loss: 0.6520 - accuracy: 0.6466 - val_loss: 0.7051 - val_accuracy: 0.6784 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.6071 - accuracy: 0.6795\n",
            "Epoch 5: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 2s 31ms/step - loss: 0.6071 - accuracy: 0.6795 - val_loss: 0.7000 - val_accuracy: 0.7137 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.5729 - accuracy: 0.6915\n",
            "Epoch 6: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 3s 58ms/step - loss: 0.5729 - accuracy: 0.6915 - val_loss: 0.7409 - val_accuracy: 0.6872 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.5438 - accuracy: 0.7186\n",
            "Epoch 7: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 2s 35ms/step - loss: 0.5438 - accuracy: 0.7186 - val_loss: 0.6958 - val_accuracy: 0.7269 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.4825 - accuracy: 0.7723\n",
            "Epoch 8: val_loss did not improve from 0.66834\n",
            "\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "59/59 [==============================] - 2s 41ms/step - loss: 0.4825 - accuracy: 0.7723 - val_loss: 0.6728 - val_accuracy: 0.7401 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.4116 - accuracy: 0.8317\n",
            "Epoch 9: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 1s 21ms/step - loss: 0.4116 - accuracy: 0.8317 - val_loss: 0.6816 - val_accuracy: 0.7665 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.3975 - accuracy: 0.8328\n",
            "Epoch 10: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 2s 27ms/step - loss: 0.3975 - accuracy: 0.8328 - val_loss: 0.6853 - val_accuracy: 0.7621 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.8440\n",
            "Epoch 11: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 2s 28ms/step - loss: 0.3807 - accuracy: 0.8440 - val_loss: 0.6832 - val_accuracy: 0.7665 - lr: 1.0000e-04\n",
            "Epoch 12/50\n",
            "59/59 [==============================] - ETA: 0s - loss: 0.3761 - accuracy: 0.8470\n",
            "Epoch 12: val_loss did not improve from 0.66834\n",
            "59/59 [==============================] - 1s 17ms/step - loss: 0.3761 - accuracy: 0.8470 - val_loss: 0.6767 - val_accuracy: 0.7753 - lr: 1.0000e-04\n",
            "Epoch 13/50\n",
            "55/59 [==========================>...] - ETA: 0s - loss: 0.3767 - accuracy: 0.8409\n",
            "Epoch 13: val_loss did not improve from 0.66834\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "59/59 [==============================] - 1s 14ms/step - loss: 0.3720 - accuracy: 0.8440 - val_loss: 0.6837 - val_accuracy: 0.7709 - lr: 1.0000e-04\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "model_history_gru = model_gru.fit(X_resampled, y_resampled,\n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs=50,\n",
        "          batch_size=64,\n",
        "          callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
        "                        filepath=\"gru_model_checkpoints/model-{epoch:02d}-{accuracy:.3f}.hdf5\",\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        save_best_only=True,\n",
        "                        verbose=1\n",
        "                    ),\n",
        "                    # learning rate drop\n",
        "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        factor=0.1,\n",
        "                        patience=5,\n",
        "                        verbose=1,\n",
        "                        min_lr=0.000001\n",
        "                    ),\n",
        "                    # early stopping\n",
        "                    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        min_delta=0.001,\n",
        "                        patience=10,\n",
        "                        verbose=1,\n",
        "                    ),\n",
        "                    # CSV logger\n",
        "                    tf.keras.callbacks.CSVLogger(\n",
        "                        filename=\"gru_model_training_log.csv\",\n",
        "                        separator=\",\",\n",
        "                        append=False\n",
        "                    )])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b53FrpsTl9M7",
        "outputId": "15e84a6e-be1d-46c2-9db5-dddc70e59401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "best_gru_model = tf.keras.models.load_model(\"/content/gru_model_checkpoints/model-07-0.661.hdf5\")\n",
        "# predict\n",
        "model_3_preds_probs = best_gru_model.predict(X_test)\n",
        "# convert model prediction probabilities to label format\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_preds_probs))\n",
        "# calculate model_1 results\n",
        "model_3 = calculate_results(y_test, model_3_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veLOyc4hm5Yw"
      },
      "source": [
        "# Model 4 (Bidirectional LSTM) ‚¨õ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLMnQjC1nM6_",
        "outputId": "4f2139ff-39c8-44d1-95fd-e4ccc64f021a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 36)]              0         \n",
            "                                                                 \n",
            " embedding_17 (Embedding)    (None, 36, 256)           2560000   \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 36, 256)           0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 36, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling1d_17  (None, 256)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,970,883\n",
            "Trainable params: 2,970,883\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# construct the model architecture\n",
        "inputs = layers.Input(shape=(max_length,))\n",
        "x = layers.Embedding(input_dim=10000, output_dim=256, input_length=max_length)(inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "x = layers.Bidirectional(layers.LSTM(128,return_sequences=True))(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dense(64, \"relu\")(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model_bd = models.Model(inputs, outputs)\n",
        "\n",
        "# compile the model\n",
        "model_bd.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "model_bd.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wCWzqJio82-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79bae0a3-4c11-47ca-c419-0fee9612938e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "3733/3738 [============================>.] - ETA: 0s - loss: 0.8503 - accuracy: 0.5556\n",
            "Epoch 1: val_loss improved from inf to 0.59282, saving model to bd_model_checkpoints/model-01-0.556.hdf5\n",
            "3738/3738 [==============================] - 40s 10ms/step - loss: 0.8501 - accuracy: 0.5559 - val_loss: 0.5928 - val_accuracy: 0.7137 - lr: 0.0010\n",
            "Epoch 2/8\n",
            "3738/3738 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.6461\n",
            "Epoch 2: val_loss improved from 0.59282 to 0.54493, saving model to bd_model_checkpoints/model-02-0.646.hdf5\n",
            "3738/3738 [==============================] - 29s 8ms/step - loss: 0.6773 - accuracy: 0.6461 - val_loss: 0.5449 - val_accuracy: 0.7974 - lr: 0.0010\n",
            "Epoch 3/8\n",
            "3737/3738 [============================>.] - ETA: 0s - loss: 0.5343 - accuracy: 0.7404\n",
            "Epoch 3: val_loss improved from 0.54493 to 0.53941, saving model to bd_model_checkpoints/model-03-0.741.hdf5\n",
            "3738/3738 [==============================] - 29s 8ms/step - loss: 0.5343 - accuracy: 0.7405 - val_loss: 0.5394 - val_accuracy: 0.7974 - lr: 0.0010\n",
            "Epoch 4/8\n",
            "3738/3738 [==============================] - ETA: 0s - loss: 0.3885 - accuracy: 0.8264\n",
            "Epoch 4: val_loss did not improve from 0.53941\n",
            "3738/3738 [==============================] - 29s 8ms/step - loss: 0.3885 - accuracy: 0.8264 - val_loss: 0.6384 - val_accuracy: 0.7533 - lr: 0.0010\n",
            "Epoch 5/8\n",
            "3732/3738 [============================>.] - ETA: 0s - loss: 0.2730 - accuracy: 0.8821\n",
            "Epoch 5: val_loss did not improve from 0.53941\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "3738/3738 [==============================] - 30s 8ms/step - loss: 0.2730 - accuracy: 0.8820 - val_loss: 0.6805 - val_accuracy: 0.7885 - lr: 0.0010\n",
            "Epoch 6/8\n",
            "3732/3738 [============================>.] - ETA: 0s - loss: 0.1537 - accuracy: 0.9408\n",
            "Epoch 6: val_loss did not improve from 0.53941\n",
            "3738/3738 [==============================] - 28s 8ms/step - loss: 0.1535 - accuracy: 0.9409 - val_loss: 0.8044 - val_accuracy: 0.7974 - lr: 1.0000e-04\n",
            "Epoch 7/8\n",
            "3734/3738 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 0.9499\n",
            "Epoch 7: val_loss did not improve from 0.53941\n",
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "3738/3738 [==============================] - 32s 9ms/step - loss: 0.1299 - accuracy: 0.9500 - val_loss: 0.8771 - val_accuracy: 0.7930 - lr: 1.0000e-04\n",
            "Epoch 8/8\n",
            "3738/3738 [==============================] - ETA: 0s - loss: 0.1141 - accuracy: 0.9548\n",
            "Epoch 8: val_loss did not improve from 0.53941\n",
            "3738/3738 [==============================] - 36s 10ms/step - loss: 0.1141 - accuracy: 0.9548 - val_loss: 0.8884 - val_accuracy: 0.7841 - lr: 1.0000e-05\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "model_history_bd = model_bd.fit(X_resampled, y_resampled,\n",
        "          validation_data=(X_test, y_test),\n",
        "          epochs=8,\n",
        "          batch_size=1,\n",
        "          callbacks=[tf.keras.callbacks.ModelCheckpoint(\n",
        "                        filepath=\"bd_model_checkpoints/model-{epoch:02d}-{accuracy:.3f}.hdf5\",\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        save_best_only=True,\n",
        "                        verbose=1\n",
        "                    ),\n",
        "                    # learning rate drop\n",
        "                    tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        factor=0.1,\n",
        "                        patience=2,\n",
        "                        verbose=1,\n",
        "                        min_lr=0.000001\n",
        "                    ),\n",
        "                    # early stopping\n",
        "                    tf.keras.callbacks.EarlyStopping(\n",
        "                        monitor=\"val_loss\",\n",
        "                        mode=\"min\",\n",
        "                        min_delta=0.001,\n",
        "                        patience=5,\n",
        "                        verbose=1,\n",
        "                    ),\n",
        "                    # CSV logger\n",
        "                    tf.keras.callbacks.CSVLogger(\n",
        "                        filename=\"bd_model_training_log.csv\",\n",
        "                        separator=\",\",\n",
        "                        append=False\n",
        "                    )])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WStdmnW6o-s-",
        "outputId": "cd84be64-eb10-4f84-95ce-03125e860c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "best_bd_model = tf.keras.models.load_model(\"/content/bd_model_checkpoints/model-03-0.741.hdf5\")\n",
        "\n",
        "# predict\n",
        "model_4_preds_probs = best_bd_model.predict(X_test)\n",
        "# convert model prediction probabilities to label format\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_preds_probs))\n",
        "# calculate model_1 results\n",
        "model_4 = calculate_results(y_test, model_4_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4Za9bC2YKle"
      },
      "source": [
        "# Feature Extraction #1 ‚¨õ\n",
        "\n",
        "**A pre-trained sentence encoder (embedding) -> Universal Sentence Encoder (USE)**\n",
        "\n",
        "**Resources**\n",
        "* If you'd want to deploy the model for mobile, a lite-version of any pre-trained model would do the work. If otherwise, stick with the large ones.\n",
        "* https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "**Import Notes:**\n",
        "* Do not import tensorflow_hub outside the scope of hub.load(\"\"). If run outside, for some unknown reason the packages throws an error.    \n",
        "* leave the input_shape as a blank list, because it has a pre-defined input_shape that we have no idea of (probably it has an input shape of 512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB1A7nk6YKKd"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "embedding_fn = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4DsjIs-iy_Z"
      },
      "outputs": [],
      "source": [
        "# Create a Keras Layer using the USE pre-trained layer from tensorflow-hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[], # check the important notes\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE_encoder\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HS3Ev7lNoLpq"
      },
      "outputs": [],
      "source": [
        "# Run this only once, otherwise the shape of the label data would look like (0.9*len(y_train),3,3).\n",
        "y_train_pre = to_categorical(y_train_pre,num_classes=3)\n",
        "y_test_pre = to_categorical(y_test_pre,num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKYV_iCiq3WX",
        "outputId": "87a0b255-28c2-41b3-db22-b186a8d250fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2037, 3) (227, 3)\n",
            "(2037,) (227,)\n"
          ]
        }
      ],
      "source": [
        "print(y_train_pre.shape, y_test_pre.shape)\n",
        "print(X_train_pre.shape, X_test_pre.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uipSeBlglTJ9",
        "outputId": "74f9b4bc-dbe2-4a96-f087-832f4a2bb476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE_encoder (KerasLayer)    (None, 512)               256797824 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 1539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 257,324,675\n",
            "Trainable params: 526,851\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# create model using the Sequential API\n",
        "model_use = tf.keras.Sequential([\n",
        "    sentence_encoder_layer,\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Dense(512, activation=\"relu\"),\n",
        "    layers.Dense(3, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model_use.compile(loss= \"categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.Adam(0.0068),\n",
        "                  metrics=[\"accuracy\"])\n",
        "model_use.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24kATD0DoGWc",
        "outputId": "3b1445ab-7095-4c9e-84fc-ded963fd06fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_use/20230604-205718\n",
            "Epoch 1/12\n",
            "64/64 [==============================] - 5s 28ms/step - loss: 0.6533 - accuracy: 0.7349 - val_loss: 0.4916 - val_accuracy: 0.8018\n",
            "Epoch 2/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.4741 - accuracy: 0.8051 - val_loss: 0.4490 - val_accuracy: 0.8106\n",
            "Epoch 3/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.4357 - accuracy: 0.8238 - val_loss: 0.5348 - val_accuracy: 0.7753\n",
            "Epoch 4/12\n",
            "64/64 [==============================] - 2s 27ms/step - loss: 0.3975 - accuracy: 0.8326 - val_loss: 0.4818 - val_accuracy: 0.8062\n",
            "Epoch 5/12\n",
            "64/64 [==============================] - 2s 26ms/step - loss: 0.3599 - accuracy: 0.8508 - val_loss: 0.4401 - val_accuracy: 0.8502\n",
            "Epoch 6/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.3120 - accuracy: 0.8807 - val_loss: 0.5180 - val_accuracy: 0.8414\n",
            "Epoch 7/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.3005 - accuracy: 0.8773 - val_loss: 0.4395 - val_accuracy: 0.8106\n",
            "Epoch 8/12\n",
            "64/64 [==============================] - 1s 18ms/step - loss: 0.2762 - accuracy: 0.8851 - val_loss: 0.5097 - val_accuracy: 0.8194\n",
            "Epoch 9/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.2665 - accuracy: 0.8920 - val_loss: 0.5094 - val_accuracy: 0.7974\n",
            "Epoch 10/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.2544 - accuracy: 0.9003 - val_loss: 0.4212 - val_accuracy: 0.8546\n",
            "Epoch 11/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.2308 - accuracy: 0.9092 - val_loss: 0.4541 - val_accuracy: 0.8194\n",
            "Epoch 12/12\n",
            "64/64 [==============================] - 1s 19ms/step - loss: 0.2219 - accuracy: 0.9121 - val_loss: 0.5118 - val_accuracy: 0.8458\n"
          ]
        }
      ],
      "source": [
        "# train the model with USE embedding\n",
        "model_history_use = model_use.fit(X_train_pre, y_train_pre,\n",
        "                                  validation_data=(X_test_pre, y_test_pre),\n",
        "                                  epochs=12,\n",
        "                                  callbacks=[create_tensorboard_callback(SAVE_DIR,\"model_use\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXNJGcS7pOjD",
        "outputId": "bdb8455e-e81b-4903-d8fa-f4e469ba6af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# Define the custom layer\n",
        "class USEEncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(USEEncoderLayer, self).__init__(**kwargs)\n",
        "        self.use_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],  # check the important notes\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE_encoder\")\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return self.use_layer(inputs)\n",
        "\n",
        "# Register the custom layer\n",
        "custom_objects = {\"USEEncoderLayer\": USEEncoderLayer, \"KerasLayer\": hub.KerasLayer}\n",
        "\n",
        "# Load the model with custom layer\n",
        "with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "    best_use_model = tf.keras.models.load_model(\"/content/use_model_checkpoints/model-01-0.743.hdf5\")\n",
        "\n",
        "# predict\n",
        "model_5_preds_probs = best_use_model.predict(X_test_pre)\n",
        "# convert model prediction probabilities to label format\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_preds_probs))\n",
        "# calculate model_1 results\n",
        "model_5 = calculate_results(y_test_pre, model_5_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86FiB7EWzt-O"
      },
      "source": [
        "# Model Performance Comparison ‚òë"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "AlExIAQdxpUK",
        "outputId": "5a4ac646-d7c5-45a7-b7c7-a1cdf3b112a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             accuracy     f1  precision  recall\n",
              "Pre-trained     0.784  0.823      0.895   0.784"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e13d8085-0b26-4322-90d3-ed2b1865ac49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Pre-trained</th>\n",
              "      <td>0.784</td>\n",
              "      <td>0.823</td>\n",
              "      <td>0.895</td>\n",
              "      <td>0.784</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e13d8085-0b26-4322-90d3-ed2b1865ac49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e13d8085-0b26-4322-90d3-ed2b1865ac49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e13d8085-0b26-4322-90d3-ed2b1865ac49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "all_model_results = pd.DataFrame({\"Dense\":model_1,\n",
        "                                  \"LSTM\":model_2,\n",
        "                                  \"GRU\":model_3,\n",
        "                                  \"Bidirectional LSTM\":model_4,\n",
        "                                  \"Pre-trained\":model_5}).T\n",
        "all_model_results[\"accuracy\"] = round(all_model_results[\"accuracy\"] / 100,3)\n",
        "all_model_results.sort_values(by=\"accuracy\",ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-1L_L1yYIrE"
      },
      "source": [
        "# Model Testing üß™"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXKkB1l4E3HO",
        "outputId": "a76a7607-432c-4c13-d3d5-b9e573256030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: \"However, the Euro 7 proposal is simply not the right way to do this, as it would have an extremely low environmental impact at an extremely high cost.\"\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Sentiment Prediction: [0.32501534 0.06486119 0.61012346]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Define the pre-processing function\n",
        "def pre_process2(text):\n",
        "    # Convert text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    punctuation = string.punctuation.replace(\"'\", \"\")\n",
        "    text = text.translate(str.maketrans('', '', punctuation))\n",
        "\n",
        "    # Remove $\n",
        "    punctuation = string.punctuation.replace(\"$\", \"\")\n",
        "    text = text.translate(str.maketrans('', '', punctuation))\n",
        "\n",
        "    # Remove stop words\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    text = \" \".join(word for word in text.split() if word not in stop_words)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Function to make prediction on new text\n",
        "def predict_sentiment(text):\n",
        "    # Preprocess the text\n",
        "    processed_text = pre_process2(text)\n",
        "\n",
        "    # Tokenize the preprocessed text\n",
        "    text_seq = tokenizer.texts_to_sequences([processed_text])\n",
        "\n",
        "    # Pad the sequence\n",
        "    text_seq_padded = pad_sequences(text_seq, maxlen=max_length)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(text_seq_padded)[0]\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Get user input\n",
        "text_input = input(\"Enter the text: \")\n",
        "\n",
        "# Make prediction\n",
        "prediction = predict_sentiment(text_input)\n",
        "print(\"Sentiment Prediction:\", prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJxj0hkVHrOh"
      },
      "outputs": [],
      "source": [
        "# Function to make prediction on new text\n",
        "def predict_sentiment2(text):\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = tf.squeeze(model_use.predict([text]))\n",
        "\n",
        "    return prediction\n",
        "\n",
        "# Get user input\n",
        "text_input = input(\"Enter the text: \")\n",
        "\n",
        "# Make prediction\n",
        "prediction = predict_sentiment2(text_input)\n",
        "print(\"Sentiment Prediction:\", prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "2q_maHOjN8tH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN1iWeiKiR2l"
      },
      "outputs": [],
      "source": [
        "# Save Model & Pipeline\n",
        "import joblib\n",
        "model_file = open(\"sentiment_classifier_model.pkl\",\"wb\")\n",
        "joblib.dump(model, model_file)\n",
        "model_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# Define the custom layer\n",
        "class USEEncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(USEEncoderLayer, self).__init__(**kwargs)\n",
        "        self.use_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],  # check the important notes\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE_encoder\")\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        return self.use_layer(inputs)\n",
        "\n",
        "# Register the custom layer\n",
        "custom_objects = {\"USEEncoderLayer\": USEEncoderLayer, \"KerasLayer\": hub.KerasLayer}\n",
        "\n",
        "# Load the model with custom layer\n",
        "with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "    best_use_model = tf.keras.models.save_model(model_use,\"/content/model_use.hdf5\")"
      ],
      "metadata": {
        "id": "HiAs1aExwNIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model with custom layer\n",
        "with tf.keras.utils.custom_object_scope(custom_objects):\n",
        "    best_use_model = tf.keras.models.load_model(\"/content/model_use.hdf5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDft-wr5xI-a",
        "outputId": "03a36ebd-2125-44ab-a8bf-09141f75e8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the text: Enter the text: mic outlook, especially in China, achieving this means shouldering the burden of cuts. The rest of the 23-nation group offered no additional action to buttress the current market, but did pledge to maintain their existing cuts until the end of 2024.\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "Sentiment Prediction: tf.Tensor([0.00611251 0.8095137  0.18437389], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Q9HQhAVPUNt9",
        "YEVrNaJrZoVe"
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "efcc119688f345fc9f4d9126933d2258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdacd15065234bc0a71805cd9325ab9c",
              "IPY_MODEL_59ec37c2e0564e4a8580526b3d523701",
              "IPY_MODEL_a79ad42126ba4a248ab77dc75a9d8f12"
            ],
            "layout": "IPY_MODEL_bd1186d7c00246579ba7c6976d2f8c72"
          }
        },
        "bdacd15065234bc0a71805cd9325ab9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e499edc3f4394b68820ebb01f9735f52",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_acd34cfac9154a498c58c1dadb66eb13",
            "value": "Downloading builder script: 100%"
          }
        },
        "59ec37c2e0564e4a8580526b3d523701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d434b7eeb704df9aa3c12f5d24c9b5d",
            "max": 6036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_402a4389303a40d0b17def8396c2eb9f",
            "value": 6036
          }
        },
        "a79ad42126ba4a248ab77dc75a9d8f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2351273be234e55930b3b4fe277e60b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3deb94759a5f40a0a9fa076c6877cca9",
            "value": " 6.04k/6.04k [00:00&lt;00:00, 270kB/s]"
          }
        },
        "bd1186d7c00246579ba7c6976d2f8c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e499edc3f4394b68820ebb01f9735f52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd34cfac9154a498c58c1dadb66eb13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d434b7eeb704df9aa3c12f5d24c9b5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "402a4389303a40d0b17def8396c2eb9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2351273be234e55930b3b4fe277e60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3deb94759a5f40a0a9fa076c6877cca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42c870a81ee245b88b53155765e26d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_591ffb4ff7ee4b528a89d8e6cf75dbc0",
              "IPY_MODEL_07e8ac75f5de4d1fabb6e9172d19fdc2",
              "IPY_MODEL_3c58f941015a406da70da053b7f63afd"
            ],
            "layout": "IPY_MODEL_baaf35b900214704b8c0ccf82c17e6f7"
          }
        },
        "591ffb4ff7ee4b528a89d8e6cf75dbc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d012481a7d42a7bc72bdf00d5fca07",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_30dd8ea95c844923bdf33c8e42f9ebd9",
            "value": "Downloading metadata: 100%"
          }
        },
        "07e8ac75f5de4d1fabb6e9172d19fdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77c1dd200e1c447f99ecb089195c9f35",
            "max": 13677,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffcc31969d5644f6880255dd4aee244a",
            "value": 13677
          }
        },
        "3c58f941015a406da70da053b7f63afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7db708f443b245bb9bd24628b390a4c9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f9be036b02f043c187385f20bb00d6d5",
            "value": " 13.7k/13.7k [00:00&lt;00:00, 453kB/s]"
          }
        },
        "baaf35b900214704b8c0ccf82c17e6f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5d012481a7d42a7bc72bdf00d5fca07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30dd8ea95c844923bdf33c8e42f9ebd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77c1dd200e1c447f99ecb089195c9f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffcc31969d5644f6880255dd4aee244a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7db708f443b245bb9bd24628b390a4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9be036b02f043c187385f20bb00d6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeef23977b2d4828b4f89a312029212c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05320d75302742eeb69c2cd9456092de",
              "IPY_MODEL_1008ddc7f2cd4011a818cf994018fe81",
              "IPY_MODEL_0ec5638f5213410196a108c75762d1a2"
            ],
            "layout": "IPY_MODEL_eda0c5000afa4c588d9c7e6d2d34f541"
          }
        },
        "05320d75302742eeb69c2cd9456092de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8050e31397284a01b14a5e5e9f06064e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4c88bceaa5484508af53002abf178a86",
            "value": "Downloading readme: 100%"
          }
        },
        "1008ddc7f2cd4011a818cf994018fe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b12a98e063b44426b3903666222b85b6",
            "max": 8862,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a4e813ddc33413daaf58572307348dc",
            "value": 8862
          }
        },
        "0ec5638f5213410196a108c75762d1a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9eed08f45616429b9c2a9a5829b9db73",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7013188432034adbb4a642e24bf421f7",
            "value": " 8.86k/8.86k [00:00&lt;00:00, 371kB/s]"
          }
        },
        "eda0c5000afa4c588d9c7e6d2d34f541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8050e31397284a01b14a5e5e9f06064e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c88bceaa5484508af53002abf178a86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b12a98e063b44426b3903666222b85b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a4e813ddc33413daaf58572307348dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9eed08f45616429b9c2a9a5829b9db73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7013188432034adbb4a642e24bf421f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b08d3aeeaed48e5a9af2aef36626e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a92e8bfbca2440abfc82eb8d17000ae",
              "IPY_MODEL_ad75b56b854c46f084c5188dc9f2302b",
              "IPY_MODEL_c7927e077c3d474f8ced40e66b833444"
            ],
            "layout": "IPY_MODEL_dad7c5211b4c41ba91d4feaac29d95d0"
          }
        },
        "4a92e8bfbca2440abfc82eb8d17000ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b77c9577864495da27320e0d05a96cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6b9c1df2079f4541bc830939a8be75a1",
            "value": "Downloading data: 100%"
          }
        },
        "ad75b56b854c46f084c5188dc9f2302b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4094b8253cb04bf49094298a9199e55e",
            "max": 681890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f514b7f067d4f3e8111ffd2c39a77d6",
            "value": 681890
          }
        },
        "c7927e077c3d474f8ced40e66b833444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35828cc245094b9392ccf2289a70fd37",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_16e8af8f1a424486b5dfb31d6ef76b0f",
            "value": " 682k/682k [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "dad7c5211b4c41ba91d4feaac29d95d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b77c9577864495da27320e0d05a96cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b9c1df2079f4541bc830939a8be75a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4094b8253cb04bf49094298a9199e55e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f514b7f067d4f3e8111ffd2c39a77d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35828cc245094b9392ccf2289a70fd37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16e8af8f1a424486b5dfb31d6ef76b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ac45ec2b9a4a10be05411c8566e212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57d5660d2c09442cbe8a5a245e13ee14",
              "IPY_MODEL_a5bac504e92343888d33a30b3ecd85d9",
              "IPY_MODEL_d72df805764c4a5bafd6880e888cbfee"
            ],
            "layout": "IPY_MODEL_fc351daac76442db9656b804b6cd2104"
          }
        },
        "57d5660d2c09442cbe8a5a245e13ee14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1f86fe5b1f1448d871f43e19e942326",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ce7de1d44deb4be287203625d1634dd5",
            "value": "Generating train split:  44%"
          }
        },
        "a5bac504e92343888d33a30b3ecd85d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f243d19b0c3d42ae9f2f8e6b9ecfd4fe",
            "max": 2264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f582e96ab67746028d6c6c797dd8fab7",
            "value": 2264
          }
        },
        "d72df805764c4a5bafd6880e888cbfee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b453aca47a40e694d19abbc38ee323",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8509d65370ff4e9fb7ecc4b460c163ff",
            "value": " 1000/2264 [00:00&lt;00:00, 6338.25 examples/s]"
          }
        },
        "fc351daac76442db9656b804b6cd2104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b1f86fe5b1f1448d871f43e19e942326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce7de1d44deb4be287203625d1634dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f243d19b0c3d42ae9f2f8e6b9ecfd4fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f582e96ab67746028d6c6c797dd8fab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b453aca47a40e694d19abbc38ee323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8509d65370ff4e9fb7ecc4b460c163ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}